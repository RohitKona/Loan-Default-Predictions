# -*- coding: utf-8 -*-
"""FraudDetection_Hyperparameter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19WxGVMOOeDVcwpPg1RqABxFYYTrT1z9G

#Executive Summary

Insurance claims fraud detection using Decision tress and random forest along with with hyperparameter tuning

Abstract: A large number of problems in data mining are related to fraud detection. Fraud is a common problem in auto insurance claims, health insurance claims, credit card transactions, financial transaction and so on. The data in this particular case comes from an actual auto insurance company. Each record represents an insurance claim. The last column in the table tells you whether the claim was fraudulent or not.

A number of people have used this dataset and here are some observations from them:

• “This is interesting data because the rules that most tools are coming up with do not make any intuitive sense. I think a lot of the tools are overfitting the data set.”

• “The other systems are producing low error rates but the rules generated make no sense.”

• “It is OK to have a higher overall error rate with simple human-understandable rules for a business use case like this.”

Attribute Information: Input variables:

MONTH: Jan through Dec.

WEEKOFMONTH: Continuous – 1 through 5.

DAYOFWEEK: Monday through Sunday.

MAKE: Acura, BMW, Chevrolet, Dodge, Ford, Toyota, VW, Nissan, etc.

ACCIDENTAREA: Urban, Rural.

DAYOFWEEKCLAIMED: Monday through Friday.

MONTHCLAIMED: Jan through Dec.

WEEKOFMONTHCLAIMED: Continuous – 1 through 5.

SEX: Male/Female.

MARITALSTATUS: Married, Single, Divorced, Widow.

AGE: continuous – 0 through 80.

FAULT: Policy_Holder, Third_Party.

POLICYTYPE: Sport-Collision, Sedan-All_Perils, Sedan-Collision, Sedan-Liability etc.

VEHICLECATEGORY: Sport, Sedan, Utility, etc.

VEHICLEPRICE: 20000_to_29000,30000_to_39000, 40000_to_59000 etc.

REPNUMBER: Continuous – 1 through 16

DEDUCTIBLE: Continuous – 300 through 700.

DRIVERRATING: Continuous – 1 through 4.

#Libraries
"""

import pandas as pd
from sklearn.preprocessing import label_binarize
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

trainData = pd.read_csv('Train (1).csv')
testData = pd.read_csv('Test (1).csv')

print(trainData.shape)
print(testData.shape)

#Understanding the Columns

trainData.info()
print()
testData.info()

# To check number of null values
trainData.isna().sum()

#To get list of names of all Columns from a dataframe

TrainCols = list(trainData.columns.values)
TestCols = list(testData.columns.values)
print(TrainCols)
print(TestCols)

#The below function returns a list of categorical features which are not numeric.
train_cat_cols = trainData.select_dtypes(exclude=['float','int']).columns #selecting the categorical columns
print(train_cat_cols.shape)
print(train_cat_cols)

categoricalFeatures = ['MONTH', 'DAYOFWEEK', 'MAKE', 'ACCIDENTAREA', 'DAYOFWEEKCLAIMED',
       'MONTHCLAIMED', 'SEX', 'MARITALSTATUS', 'FAULT', 'POLICYTYPE',
       'VEHICLECATEGORY', 'VEHICLEPRICE', 'DAYS_POLICY_ACCIDENT',
       'DAYS_POLICY_CLAIM', 'PASTNUMBEROFCLAIMS', 'AGEOFVEHICLE',
       'AGEOFPOLICYHOLDER', 'POLICEREPORTFILED', 'WITNESSPRESENT', 'AGENTTYPE',
       'NUMBEROFSUPPLIMENTS', 'ADDRESSCHANGE_CLAIM', 'NUMBEROFCARS',
       'BASEPOLICY']

# Seperate Target column from Train Data
Xtrain = trainData[TrainCols[0:len(TrainCols)-1]].copy()
Ytrain = trainData[['FRAUDFOUND']].copy()
print("Train Set shape:")
print(Xtrain.shape)
print(Ytrain.shape)
Xtest = testData[TestCols[0:len(TestCols)-1]].copy()
Ytest = testData[['FRAUDFOUND']].copy()
print("Test Set shape:")
print(Xtest.shape)
print(Ytest.shape)

# OneHotEncoding on Train
ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)
Xcat = pd.DataFrame(ohe.fit_transform(Xtrain[categoricalFeatures]), columns=ohe.get_feature_names_out(input_features=categoricalFeatures), index=Xtrain.index)
Xtrain = pd.concat([Xtrain,Xcat],axis=1)
Xtrain.drop(labels=categoricalFeatures,axis=1,inplace=True)
Xtrain.sample(5)

# OneHotEncoding on Test
Xcat = pd.DataFrame(ohe.transform(Xtest[categoricalFeatures]), columns=ohe.get_feature_names_out(input_features=categoricalFeatures), index=Xtest.index)
Xtest = pd.concat([Xtest, Xcat], axis=1)
Xtest.drop(labels=categoricalFeatures, axis=1, inplace=True)
Xtest.sample(5)

dt = DecisionTreeClassifier()
dt.fit(Xtrain, Ytrain)

rf = RandomForestClassifier()
rf.fit(Xtrain, Ytrain)

# Predictions on the test and train data using Decision Tree model
X_test_pred = dt.predict(Xtest)
X_train_pred = dt.predict(Xtrain)

# Model Accuracy
print('Basic Decision Tree')
print("Train Accuracy:", metrics.accuracy_score(Ytrain, X_train_pred))
print("Test Accuracy:", metrics.accuracy_score(Ytest, X_test_pred))

# Confusion Matrix for Decision Tree
print("Confusion Matrix for Decision Tree:")
print(confusion_matrix(Ytest, X_test_pred))

# Max Depth and Number of Leaves in the Decision Tree
print("Max Depth:", dt.get_depth())
print("Number of Leaves:", dt.get_n_leaves())

# Printing precision, recall, and other classification metrics
print('Printing precision, recall, and other metrics')
print(metrics.classification_report(Ytest, X_test_pred))

X_testPred1 = rf.predict(Xtest)
XPred1 = rf.predict(Xtrain)
#Model Accuracy
print("Basic Random Forest")
print("Train Accuracy:", metrics.accuracy_score(Ytrain,XPred1))
print("Test Accuracy:", metrics.accuracy_score(Ytest,X_testPred1))
print("Confusion Matrix for Random Forest:")
print(confusion_matrix(Ytest,X_testPred1))
print('Printing the precision and recall, among other metrics')
print(metrics.classification_report(Ytest, X_testPred1))

#Hyperparameter tuning done for decision tree classifier
#RANDOM SEARCH
import time
start_time = time.time()

print("RandomizedSearchCV-Decision tree")
parameters={'min_samples_leaf' : range(10,300,10),'max_depth':
            range(1,50,2),'criterion':['gini','entropy','log_loss'],
            'max_features' :range(10,30,20),'max_leaf_nodes': range(10,20,2)}
dt_random = RandomizedSearchCV(dt,parameters,n_iter=25,cv=5)
dt_random.fit(Xtrain, Ytrain)
grid_parm=dt_random.best_params_
print(grid_parm)
print("accuracy Score for Decision Tree:{0:6f}".
      format(dt_random.score(Xtest,Ytest)))

print("--- %s seconds ---" % (time.time() - start_time))

#GRID SEARCH----------------------------------------

import time
start_time = time.time()

print("GridSearchCV-Decision tree")
dt_grid = GridSearchCV(dt,parameters)
dt_grid.fit(Xtrain, Ytrain)
grid_parm1=dt_grid.best_params_
print(grid_parm1)
print("accuracy Score for Decision Tree:{0:6f}".
      format(dt_grid.score(Xtest,Ytest)))

print("--- %s seconds ---" % (time.time() - start_time))

#Using the parameters obtained from HyperParameterTuning in the DecisionTreeClassifier
dtRand = DecisionTreeClassifier(**grid_parm)
dtGrid = DecisionTreeClassifier(**grid_parm1)

dtRand.fit(Xtrain,Ytrain)
dtRand_predict = dtRand.predict(Xtest)
dtGrid.fit(Xtrain,Ytrain)
dtGrid_predict = dtGrid.predict(Xtest)

# Accuracy for Decision Tree using Random Search CV for Hyperparameter Tuning

print("Test Accuracy:", metrics.accuracy_score(Ytest,dtRand_predict))
print("Confusion Matrix for Decision Tree:")
print(confusion_matrix(Ytest,dtRand_predict))
print('Printing the precision and recall, among other metrics')
print(metrics.classification_report(Ytest, dtRand_predict))
print('Cross validation score for stratified 5 fold')
clf_cv_score = cross_val_score(dtRand, Xtrain, Ytrain, cv=5, scoring="balanced_accuracy")
print(clf_cv_score)

# Accuracy for Decision Tree using Grid Search for Hyperparameter Tuning

print("Test Accuracy:", metrics.accuracy_score(Ytest,dtGrid_predict))
print("Confusion Matrix for Decision Tree:")
print(confusion_matrix(Ytest,dtGrid_predict))
print('Printing the precision and recall, among other metrics')
print(metrics.classification_report(Ytest, dtGrid_predict))
print('Cross validation score for stratified 5 fold')
clf_cv_score = cross_val_score(dtGrid, Xtrain, Ytrain, cv=5, scoring="balanced_accuracy")
print(clf_cv_score)

#Hyperparameter tuning done for random forest classifier

#RANDOM SEARCH--------------------------------------------

import time
start_time = time.time()

print("RandomizedSearchCV-Random forest")
rand_parameters={'min_samples_leaf' : range(10,100,10),'max_depth':
            range(1,10,2),'max_features':[10,20,30],'n_estimators':[20,30,40]}
rf_random = RandomizedSearchCV(rf,rand_parameters,n_iter=25,cv=5)
rf_random.fit(Xtrain, Ytrain)
grid_parm=rf_random.best_params_
print(grid_parm)
print("accuracy Score for Random Forest:{0:6f}".
      format(rf_random.score(Xtest,Ytest)))

print("--- %s seconds ---" % (time.time() - start_time))

import time
start_time = time.time()

print("GridSearchCV-Random Forest")
rf_grid = GridSearchCV(rf,rand_parameters)
rf_grid.fit(Xtrain, Ytrain)
grid_parm1=rf_grid.best_params_
print(grid_parm1)
print("accuracy Score for Random Foret:{0:6f}".
      format(rf_grid.score(Xtest,Ytest)))

print("--- %s seconds ---" % (time.time() - start_time))

#Using the parameters obtained from HyperParameterTuning in the RandomForestClassifier
rfRand = RandomForestClassifier(**grid_parm)
rfGrid = RandomForestClassifier(**grid_parm1)

rfRand.fit(Xtrain,Ytrain)
rfRand_predict = rfRand.predict(Xtest)
rfGrid.fit(Xtrain,Ytrain)
rfGrid_predict = rfGrid.predict(Xtest)

# Accuracy for Random Forest using Random Search CV for Hyperparameter Tuning

print("Test Accuracy:", metrics.accuracy_score(Ytest,rfRand_predict))
print("Confusion Matrix for Random Forest:")
print(confusion_matrix(Ytest,rfRand_predict))
print('Printing the precision and recall, among other metrics')
print(metrics.classification_report(Ytest, rfRand_predict))
print('cross validation score for random forst')
clf_cv_score = cross_val_score(rfRand, Xtrain, Ytrain, cv=5, scoring="balanced_accuracy")
print(clf_cv_score)

# Accuracy for Random Forest using Grid Search for Hyperparameter Tuning

print("Test Accuracy:", metrics.accuracy_score(Ytest,rfGrid_predict))
print("Confusion Matrix for Random Forest:")
print(confusion_matrix(Ytest,rfGrid_predict))
print('Printing the precision and recall, among other metrics')
print(metrics.classification_report(Ytest, rfGrid_predict))
print('cross validation score')
clf_cv_score = cross_val_score(rfGrid, Xtrain, Ytrain, cv=5, scoring="balanced_accuracy")
print(clf_cv_score)

